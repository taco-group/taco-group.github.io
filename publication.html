<!DOCTYPE html>
<html lang="en">

<head>
    <title>TACO-Group@TAMU</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
        integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

    <div class="site-wrap">

        <div class="site-mobile-menu site-navbar-target">
            <div class="site-mobile-menu-header">
                <div class="site-mobile-menu-close mt-3">
                    <span class="icon-close2 js-menu-toggle"></span>
                </div>
            </div>
            <div class="site-mobile-menu-body"></div>
        </div>

        <div class="header-top">
            <div class="container" style="padding:20px">
                <div class="row align-items-center">
                    <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./TACO_LOGO.png" width="25%" />
                    <a class="ml-auto site-logo">
                        <b style="color: rgb(80, 0, 0)">T</b>rustworthy, <b
                            style="color: rgb(80, 0, 0)">A</b>utonomous, Human-<b
                            style="color: rgb(80, 0, 0)">C</b>entered, and<br> Emb<b
                            style="color: rgb(80, 0, 0)">o</b>died Intelligence Group @ Texas A&M University
                    </a>
                    <a href="#"
                        class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                    <!-- </div> -->
                    <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                    <!--          <div class="col-6 d-block d-lg-none text-right">-->

                </div>
            </div>
        </div>


        <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

            <div class="container" style="padding-right=10%">
                <div class="d-flex align-items-right">
                    <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                    <div class="ml-auto">
                        <nav class="site-navigation position-relative text-right" role="navigation">
                            <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                                <li class="active">
                                    <a href="index.html" class="nav-link text-right">Home</a>
                                </li>
<!--                                <li>-->
<!--                                    <a href="research.html"" class=" nav-link text-left">Research</a>-->
<!--                                </li>-->
                                <li>
                                    <a href="publication.html" class=" nav-link text-left">Publication</a>
                                </li>
                                <li>
                                    <a href="teaching.html" class=" nav-link text-left">Teaching</a>
                                </li>
                                <li>
                                    <a href="group.html" class="nav-link text-left">Group</a>
                                </li>
                                <li>
                                    <a href="resource.html" class="nav-link text-left">Resource</a>
                                </li>
<!--                                <li>-->
<!--                                    <a href="prospective_students.html" class="nav-link text-left">Opening</a>-->
<!--                                </li>-->
                                <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                            </ul>
                        </nav>

                    </div>

                </div>
            </div>

        </div>

    </div>



    <div class="site-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <p>
<!--                        Our group actively publishes in the fields of design automation, machine learning, computer-->
<!--                        architecture, and photonics. Below are a list of recent and selected papers.-->
                        <!-- A mark * denotes the author to be a ScopeX student or Dr. Gu's mentee. -->
                        Our group actively publishes in top-tier venues in the fields of machine learning, computer vision, natural language processing, and interdisciplinary data science.
                        Below is a list of recent and selected papers.
<!--                        Our group actively publishes in the fields of machine learning, computer vision, and interdisciplinary data science. Below are a list of recent and selected papers. A mark * denotes the author to be a VITA student or Dr. Wang's mentee. An up-to-date full paper list can be found here.-->
                        </p>
                    <!-- Journal paper -->
                    <div class="section-title" style="margin-bottom: 20px">
                        <h2>Preprint</h2>
                    </div>

                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>
                                <li>TrustGen Team.
                                <br> <b style="color:rgb(71, 71, 71)">"On the Trustworthiness of Generative Foundation Models – Guideline, Assessment, and Perspective"</b>
                                <br>Arxiv 2025. <a href="https://arxiv.org/abs/2502.14296">[Paper]</a> <a href="https://trustgen.github.io/">[Project]</a></li>

                                <li>S. Xing, Y. Wang, P. Li, R. Bai, Y. Wang, C. Qian, H. Yao, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization"</b>
                                <br>Arxiv 2025. <a href="https://arxiv.org/abs/2502.13146">[Paper]</a> <a href="https://taco-group.github.io/Re-Align/">[Project]</a></li>


                                <li>S. Xing, H. Hua, X. Gao, S. Zhu, R. Li, K. Tian, X. Li, H. Huang, T. Yang, Z. Wang, Y. Zhou, H. Yao, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2412.15206">[Paper]</a> <a href="https://taco-group.github.io/AutoTrust/">[Project]</a></li>

                                <li>X. Xing, C. Qian, Y. Wang, H. Hua, K. Tian, Y. Zhou, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2412.15208">[Paper]</a> <a href="https://github.com/taco-group/OpenEMMA">[Code]</a></li>

                                <li>L. Li, J. Li, ..., Z. Tu, ..., Y. Zhao, Y. Dong
                                <br> <b style="color:rgb(71, 71, 71)">"Political-llm: Large language models in political science"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2412.06864">[Paper]</a> <a href="http://political-llm.org/">[Project]</a></li>

                                <li>Z. Wang, J. Guo, J. Zhu, Y. Li, H. Huang, M. Chen, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2412.04852">[Paper]</a> <a href="https://github.com/taco-group/SleeperMark">[Code]</a></li>

                                <li>Q. Zheng, Y. Fan, L. Huang, T. Zhu, J. Liu, Z. Hao, X. Shuo, C.J. Chen, X. Min, A. Bovik, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"Video Quality Assessment: A Comprehensive Survey"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2412.04508">[Paper]</a> <a href="https://github.com/taco-group/Video-Quality-Assessment-A-Comprehensive-Survey">[Code]</a></li>

                                <li>H. Wang, Y. Zhang, R. Bai, Y. Zhao, S. Liu, Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2411.16832">[Paper]</a> <a href="https://github.com/taco-group/FaceLock">[Code]</a></li>


                                <li>S. Li, H. Gong, H. Dong, T. Yang, Z. Tu, Y. Zhao
                                <br> <b style="color:rgb(71, 71, 71)">"DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2411.08227">[Paper]</a> <a href="https://github.com/lili0415/DPU-OOD-Detection">[Code]</a></li>

                                <li>R. Li, P. Pan, B. Yang, D. Xu, S. Zhou, X. Zhang, Z. Li, A. Kadambi, Z. Wang, Z. Tu, Z. Fan
                                <br> <b style="color:rgb(71, 71, 71)">"4K4DGen: Panoramic 4D Generation at 4K Resolution"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2406.13527">[Paper]</a> <a href="https://4k4dgen.github.io/">[Project]</a></li>

                                <li>T. Zhu, Q. Liu, F. Wang, Z. Tu, and M. Chen
                                <br> <b style="color:rgb(71, 71, 71)">"Unraveling Cross-Modality Knowledge Conflict in Large Vision-Language Models"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2410.03659">[Paper]</a> <a href="https://github.com/luka-group/vlm-knowledge-conflict">[Code]</a></li>

                                <li>J. Li, X. Liu, B. Li, R. Xu, J. Li, H. Yu, and Z. Tu
                                <br> <b style="color:rgb(71, 71, 71)">"CoMamba: Real-time Cooperative Perception Unlocked with State Space Models"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2409.10699">[Paper]</a> <a href="https://github.com/taco-group/CoMamba">[Code]</a></li>

<!--                                <li>K. Mei, Z. Tu, M. Delbracio, H. Talebi, V.M. Patel, P. Milanfar-->
<!--                                <br> <b style="color:rgb(71, 71, 71)">"Bigger is not Always Better: Scaling Properties of Latent Diffusion Models"</b>-->
<!--                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2404.01367">[Paper]</a> </li>-->

                                <li>B Li, J Li, X Liu, R Xu, Z Tu, J Guo, X Li, H Yu
                                <br> <b style="color:rgb(71, 71, 71)">"V2X-DGW: Domain Generalization for Multi-agent Perception under Adverse Weather Conditions"</b>
                                <br>Arxiv 2024. <a href="https://arxiv.org/abs/2403.11371">[Paper]</a> </li>
                            </ul>
                        </div>
                    </div>


                    <div class="section-title" style="margin-bottom: 20px">
                        <h2>Journal Paper</h2>
                    </div>
<!--                    <div class="section-title" style="margin-bottom: 10px">-->
<!--                        <h3>-->
<!--                            <font size="4"> 2024</font>-->
<!--                        </h3>-->
<!--                    </div>-->
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>
                                <li>Z. Tu, C.J. Chen, J. Lin, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                                    <br> <b style="color:rgb(71, 71, 71)">"Understanding, detecting, and removing perceptual banding artifacts in compressed videos"</b>
                                    <br>Signal Processing: Image Communication, 2025. <a href="https://www.sciencedirect.com/science/article/pii/S0923596525001183">[Paper]</a> <a href="https://github.com/vztu/DebandingNet">[Code]</a></li>
                                <li>R. Zhu, Z. Tu, J. Liu, A.C. Bovik, Y. Fan
                                    <br> <b style="color:rgb(71, 71, 71)">"MWFormer: Multi-Weather Image Restoration Using Degradation-Aware Transformers"</b>
                                    <br>IEEE Transactions on Image Processing, 2024. <a href="">[Paper]</a> <a href="">[Code]</a></li>
                                <li>K. Mei, Z. Tu, M. Delbracio, H. Talebi, V. M. Patel, P. Milanfar
                                    <br> <b style="color:rgb(71, 71, 71)">"Bigger is not Always Better: Scaling Properties of Latent Diffusion Models"</b>
                                    <br>Transactions on Machine Learning Research, 2024. <a href="https://arxiv.org/abs/2404.01367">[Paper]</a> <a href="https://openreview.net/forum?id=0u7pWfjri5">[Openreview]</a></li>
                                <li>R. Xu, C.J. Chen, Z. Tu, M.H. Yang
                                    <br> <b style="color:rgb(71, 71, 71)">"V2X-ViTv2: Improved Vision Transformers for Vehicle-to-Everything Cooperative Perception"</b>
                                    <br>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024. <a href="https://ieeexplore.ieee.org/abstract/document/10715696">[Paper]</a> <a href="https://github.com/DerrickXuNu/OpenCOOD">[Code]</a></li>
                                <li>Q. Zheng*, Z. Tu*, PC Madhusudana, X. Zeng, A.C. Bovik, Y. Fan
                                    <br> <b style="color:rgb(71, 71, 71)">"FAVER: Blind Quality Prediction of Variable Frame Rate Videos"</b>
                                    <br>Signal Processing: Image Communication, 2024. <a href="https://www.sciencedirect.com/science/article/abs/pii/S092359652400002X">[Paper]</a> <a href="https://github.com/uniqzheng/HFR-BVQA">[Code]</a></li>
                                <li>Q. Zheng, Z. Tu, X. Zeng, AC Bovik, Y. Fan
                                    <br> <b style="color:rgb(71, 71, 71)">"A completely blind video quality evaluator"</b>
                                    <br>IEEE Signal Processing Letters, 2022. <a href="https://ieeexplore.ieee.org/abstract/document/9921340">[Paper]</a> <a href="https://github.com/uniqzheng/VIQE">[Code]</a></li>
                                <li>Z. Tu, X. Yu, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                                    <br> <b style="color:rgb(71, 71, 71)">"RAPIQUE: Rapid and accurate video quality prediction of user generated content"</b>
                                    <br>IEEE Open Journal of Signal Processing, 2021. <a href="https://ieeexplore.ieee.org/abstract/document/9463703">[Paper]</a> <a href="https://github.com/vztu/RAPIQUE">[Code]</a> <a href="https://signalprocessingsociety.org/blog/sps-webinar-rapid-accurate-and-explainable-video-quality-assessment-user-generated-content">[IEEE SPS Webinar]</a><br><b><font color="red">Highlighted in OJSP 2022-2023 newsletter, featured talk at IEEE SPS Webinar</a></font></b></br></li>
                                <li>Z. Tu, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                                    <br> <b style="color:rgb(71, 71, 71)">"UGC-VQA: Benchmarking blind video quality assessment for user generated content"</b>
                                    <br>IEEE Transactions on Image Processing, 2021. <a href="https://arxiv.org/abs/2005.14354">[Paper]</a> <a href="https://github.com/vztu/VIDEVAL">[Code]</a>   </li>
                                <li>Z. Tu, J. Lin, Y. Wang, B. Adsumilli, A.C. Bovik
                                    <br> <b style="color:rgb(71, 71, 71)">"Adaptive Debanding Filter"</b>
                                    <br>IEEE Signal Processing Letters, 2020. <a href="https://arxiv.org/abs/2009.10804">[Paper]</a> <a href="https://github.com/google/bband-adaband">[Code]</a></li>

                            </ul>
                        </div>
                    </div>
                    <!-- Conference paper -->
                    <div class="section-title" style="margin-bottom: 20px">
                        <h2>Conference Paper</h2>
                    </div>
                    <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2025</font>
                        </h3>
                    </div>

                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                             <li>J Li, X Liu, B Li, R Xu, J Li, H Yu, Z Tu
                            <br> <b style="color:rgb(71, 71, 71)">"CoMamba: Real-time cooperative perception unlocked with state space models"</b>
                                <br>International Conference on Intelligent Robots and Systems (IROS), 2025.
                                <a href="https://taco-group.github.io/CoMamba/">[Project]</a>
                                <a href="https://arxiv.org/abs/2409.10699">[Paper]</a>
                            </li>

                             <li>R Wang, X Gao, H Xiang, R Xu, Z Tu
                            <br> <b style="color:rgb(71, 71, 71)">"CoCMT: Communication-efficient cross-modal transformer for collaborative perception"</b>
                                <br>International Conference on Intelligent Robots and Systems (IROS), 2025.
                                <a href="https://github.com/taco-group/COCMT">[Project]</a>
                                <a href="https://arxiv.org/abs/2503.13504">[Paper]</a>
                            </li>


                             <li>S Li, P Cai, Y Zhou, Z Ni, R Liang, Y Qin, Y Nian, Z Tu, X Hu, Y Zhao
                            <br> <b style="color:rgb(71, 71, 71)">"Secure on-device video ood detection without backpropagation"</b>
                                <br>International Conference on Computer Vision (ICCV), 2025.
                                <a href="https://github.com/Dystopians/SecDOOD">[Project]</a>
                                <a href="https://arxiv.org/abs/2503.06166">[Paper]</a>
                            </li>


                             <li>Y Wang, X Huang, X Sun, M Yan, S Xing, Z Tu, J Li
                            <br> <b style="color:rgb(71, 71, 71)">"Uniocc: A unified benchmark for occupancy forecasting and prediction in autonomous driving"</b>
                                <br>International Conference on Computer Vision (ICCV), 2025.
                                <a href="https://github.com/tasl-lab/UniOcc">[Project]</a>
                                <a href="https://arxiv.org/abs/2503.24381">[Paper]</a>
                            </li>


                             <li>X Gao, Y Wu, R Wang, C Liu, Y Zhou, Z Tu
                            <br> <b style="color:rgb(71, 71, 71)">"LangCoop: Collaborative driving with language"</b>
                                <br>Computer Vision and Pattern Recognition (CVPR) MEIS Workshop, 2025. <b><font color="red">Best Paper Award</a></font></b>
                                <a href="https://github.com/taco-group/LangCoop">[Project]</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2025W/MEIS/html/Gao_LangCoop_Collaborative_Driving_with_Language_CVPRW_2025_paper.html">[Paper]</a>
                            </li>


                            <li>Z Wang, J Guo, J Zhu, Y Li, H Huang, M Chen, Z Tu
                            <br> <b style="color:rgb(71, 71, 71)">"SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models"</b>
                                <br>Computer Vision and Pattern Recognition (CVPR), 2025.
                                <a href="https://github.com/taco-group/FaceLock">[Project]</a>
                                <a href="https://arxiv.org/abs/2411.16832">[Paper]</a>
                            </li>

                            <li>
                            <br> <b style="color:rgb(71, 71, 71)">"SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models"</b>
                                <br>Computer Vision and Pattern Recognition (CVPR), 2025.
                                <a href="https://github.com/taco-group/SleeperMark">[Project]</a>
                                <a href="https://arxiv.org/abs/2412.04852">[Paper]</a>
                            </li>


                            <li>S Li, H Gong, H Dong, T Yang, Z Tu, Y Zhao
                            <br> <b style="color:rgb(71, 71, 71)">"DPU: Dynamic prototype updating for multimodal out-of-distribution detection "</b>
                                <br>Computer Vision and Pattern Recognition (CVPR), 2025. <b><font color="red">Highlight</a></font></b>
                                <a href="https://github.com/lili0415/DPU-OOD-Detection">[Project]</a>
                                <a href="https://arxiv.org/abs/2411.08227">[Paper]</a>
                            </li>


                            <li>B Li, J Li, X Liu, R Xu, Z Tu, J Guo, X Li, H Yu
                            <br> <b style="color:rgb(71, 71, 71)">"V2X-DGW: Domain Generalization for Multi-agent Perception under Adverse Weather Conditions"</b>
                                <br>International Conference on Robotics and Automation (ICRA), 2025.
                                <a href="https://github.com/Baolu1998/V2X-DGW">[Project]</a>
                                <a href="https://https://arxiv.org/abs/2403.11371">[Paper]</a>
                                <a href="">[Code]</a>
                            </li>

                            <li>R. Li, P. Pan, B. Yang, D. Xu, S. Zhou, X. Zhang, Z. Li, A. Kadambi, Z. Wang, Z. Tu, Z. Fan
                            <br> <b style="color:rgb(71, 71, 71)">"4k4dgen: Panoramic 4d generation at 4k resolution"</b>
                                <br>International Conference on Learning Representations (ICLR), 2025. <b><font color="red">Spotlight</a></font></b>
                                <a href="https://4k4dgen.github.io/">[Project]</a>
                                <a href="https://arxiv.org/abs/2406.13527">[Paper]</a>
                                <a href="">[Code]</a>
                            </li>

                            <li>X. Gao, R. Xu, J. Li, Z. Wang, Z. Fan, Z. Tu
                            <br> <b style="color:rgb(71, 71, 71)">"STAMP: Scalable Task- And Model-agnostic Collaborative Perception"</b>
                                <br>International Conference on Learning Representations (ICLR), 2025.
                                <a href="https://xiangbogaobarry.github.io/STAMP/">[Project]</a>
                                <a href="https://github.com/taco-group/STAMP">[Code]</a>
                            </li>

                            </ul>
                        </div>
                    </div>


                    <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2024</font>
                        </h3>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                            <li>C.-J. Chen, R. Xu, W. Shao, J. Zhang, Z. Tu
                            <br> <b style="color:rgb(71, 71, 71)">"OpenCDA-&infin;: A Closed-loop Benchmarking Platform for End-to-end Evaluation of Cooperative Perception"</b>
                                <br>NeurIPS Dataset and Benchmark Track (NeurIPS), 2024.
                                <a href="https://openreview.net/forum?id=ioAPiwNBE9#discussion">[Paper]</a>
                                <a href="https://github.com/taco-group/opencda-loop">[Code]</a>
                            </li>


                            <li>C. Qi, Z. Tu, K. Ye, M. Delbracio, P. Milanfar, Q. Chen, H. Talebi
                            <br> <b style="color:rgb(71, 71, 71)">"SPIRE: Semantic Prompt-Driven Image Restoration "</b>
                                <br>European Conference on Computer Vision (ECCV), 2024.
                                <a href="https://chenyangqiqi.github.io/tip/">[Project]</a>
                                <a href="https://arxiv.org/abs/2312.11595">[Paper]</a>
                            </li>

                            <li>K. Mei, M. Delbracio, H. Talebi, Z. Tu, V.M. Patel, P. Milanfar
                            <br> <b style="color:rgb(71, 71, 71)">"CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation"</b>
                                <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.
                                <a href="https://fast-codi.github.io/">[Project]</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Mei_CoDi_Conditional_Diffusion_Distillation_for_Higher-Fidelity_and_Faster_Image_Generation_CVPR_2024_paper.html">[Paper]</a> <a href="https://github.com/fast-codi/CoDi">[Code]</a>
                            </li>

                            <li>J. Li, B. Li, Z. Tu, X. Liu, Q. Guo, F. Juefei-Xu, R. Xu, H. Yu
                            <br> <b style="color:rgb(71, 71, 71)">"Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving"</b>
                                <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.
                                <a href="https://jinlong17.github.io/LightDiff/">[Project]</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Light_the_Night_A_Multi-Condition_Diffusion_Framework_for_Unpaired_Low-Light_CVPR_2024_paper.html">[Paper]</a> <a href="https://github.com/jinlong17/LightDiff">[Code]</a>
                            </li>

                            </ul>
                        </div>
                    </div>

                    <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2023</font>
                        </h3>
                    </div>

                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>
                            <li>Z. Tu, P. Milanfar, H. Talebi
                            <br> <b style="color:rgb(71, 71, 71)">"MULLER: Multilayer Laplacian Resizer for Vision"</b>
                                <br>IEEE/CVF International Conference on Computer Vision (ICCV), 2023.
                                <a href="https://arxiv.org/abs/2304.02859">[Paper]</a> <a href="https://github.com/google-research/google-research/tree/master/muller">[Code]</a>
                            </li>

                            <li>R. Xu, X. Xia, J. Li, H. Li, S. Zhang, Z. Tu, Z. Meng, H. Xiang, X. Dong, R. Song, H. Yu, B. Zhou, J. Ma
                            <br> <b style="color:rgb(71, 71, 71)">"V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception"</b>
                                <br>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR), 2023. <b><font color="red">Highlight</a></font></b>
                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>
                                <a href="https://arxiv.org/abs/2303.07601">[Paper]</a> <a href="https://github.com/ucla-mobility/v2v4real">[Code]</a>
                            </li>

                            </ul>
                        </div>
                    </div>
                    <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2022</font>
                        </h3>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                                <li>Q. Zheng, Z. Tu, Z. Hao, X. Zeng, A.C. Bovik, Y. Fan
                            <br> <b style="color:rgb(71, 71, 71)">"Blind Video Quality Assessment via Space-Time Slice Statistics"</b>
                                <br>IEEE International Conference on Image Processing (ICIP), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9897565/">[Paper]</a> <a href="https://github.com/uniqzheng/STS_BVQA">[Code]</a>
                            </li>

                                <li>R Xu*, Z Tu*, H Xiang, W Shao, B Zhou, J Ma
                            <br> <b style="color:rgb(71, 71, 71)">"CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers"</b>
                                <br>Conference on Robot Learning (CoRL), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://arxiv.org/abs/2207.02202">[Paper]</a> <a href="https://github.com/DerrickXuNu/CoBEVT">[Code]</a>
                            </li>


                                <li>Q. Zheng, Z. Tu, Y. Fan, X. Zeng, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"No-Reference Quality Assessment of Variable Frame-Rate Videos Using Temporal Bandpass Statistics"</b>
                                <br>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9746997">[Paper]</a> <a href="https://github.com/uniqzheng/HFR-BVQA">[Code]</a>
                            </li>


                            <li>R Xu*, Z Tu*, Y Du*, X Dong, J Li, Z Meng, J Ma, A Bovik, H Yu
                            <br> <b style="color:rgb(71, 71, 71)">"Pik-Fix: Restoring and Colorizing Old Photos"</b>
                                <br>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://arxiv.org/abs/2205.01902">[Paper]</a> <a href="https://github.com/DerrickXuNu/Pik-Fix">[Code]</a>
                            </li>

                            <li>Z. Tu, H. Talebi, H. Zhang, F. Yang, P. Milanfar, A. Bovik, Y. Li
                            <br> <b style="color:rgb(71, 71, 71)">"MaxViT: Multi-axis Vision Transformer"</b>
                                <br>European Conference on Computer Vision (ECCV), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://arxiv.org/abs/2204.01697">[Paper]</a> <a href="https://github.com/google-research/maxvit">[Code]</a>
                                <br><b><font color="red">Highlighted on-top in Jeff Dean's <a href="https://blog.research.google/2023/01/google-research-2022-beyond-language.html">2022 Annual Google Research Blog</a>; Selected as top-3 papers of the year in <a href="https://www.linkedin.com/pulse/ahead-ai-4-big-year-sebastian-raschka-phd/?trk=public_post">Ahead of AI #4: A Big Year for AI</a>; Retweeted by the Yann Lecun: <a href="https://twitter.com/ylecun/status/1579587264010600448?lang=en">link</a>;
                                 Most Influential ECCV Papers #8 (<a href="https://www.paperdigest.org/2024/09/most-influential-eccv-papers-2024-09/>">2024-09</a>)</font></b>
                            </li>


                            <li>R. Xu*, H. Xiang*, Z. Tu*, X. Xia, M.H. Yang, J. Ma
                            <br> <b style="color:rgb(71, 71, 71)">"V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer"</b>
                                <br>European Conference on Computer Vision (ECCV), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://arxiv.org/abs/2203.10638">[Paper]</a> <a href="https://github.com/DerrickXuNu/v2x-vit">[Code]</a>
                            </li>

                            <li>Z. Tu, H. Talebi, H. Zhang, F. Yang, P. Milanfar, A. Bovik, Y. Li
                            <br> <b style="color:rgb(71, 71, 71)">"MAXIM: Multi-Axis MLP for Image Processing"</b>
                                <br>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR), 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://arxiv.org/abs/2201.02973">[Paper]</a> <a href="https://github.com/google-research/maxim">[Code]</a>
                                <br><b><font color="red">Best paper nomination award (0.4% of 8161 submissions)</font></b>
                            </li>
                            </ul>
                        </div>
                    </div>


                    <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2021</font>
                        </h3>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                            <li>Z. Tu, C.J. Chen, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"Video quality assessment of user generated content: A benchmark study and a new model"</b>
                                <br>IEEE International Conference on Image Processing (ICIP), 2021.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9506189">[Paper]</a> <a href="https://github.com/vztu/VIDEVAL_release">[Code]</a>
                            </li>

                            <li>Z. Tu, C.J. Chen, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"A Temporal Statistics Model For UGC Video Quality Prediction"</b>
                                <br>IEEE International Conference on Image Processing (ICIP), 2021.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9506669">[Paper]</a>
                            </li>

                            <li>Z. Tu, C.J. Chen, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"Efficient user-generated video quality prediction"</b>
                                <br>Picture Coding Symposium (PCS), 2021.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9477483">[Paper]</a> <a href="https://github.com/vztu/RAPIQUE">[Code]</a>
                            </li>

                            <li>Z. Tu, C.J. Chen, L.H. Chen, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"Regression or classification? new methods to evaluate no-reference picture and video quality models"</b>
                                <br>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9414232">[Paper]</a>
                            </li>


                            </ul>
                        </div>

                 </div>


                 <div class="section-title" style="margin-bottom: 10px">
                        <h3>
                            <font size="4"> 2020</font>
                        </h3>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                            <li>Z. Tu, L.H. Chen, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"A comparative evaluation of temporal pooling methods for blind video quality assessment"</b>
                                <br>IEEE International Conference on Image Processing (ICIP), 2020.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9191169">[Paper]</a>
                            </li>

                            <li>Z. Tu, J. Lin, Y. Wang, N. Birkbeck, B. Adsumilli, A.C. Bovik
                            <br> <b style="color:rgb(71, 71, 71)">"BBAND Index: a No-Reference Banding Artifact Predictor"</b>
                                <br>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://ieeexplore.ieee.org/abstract/document/9053634">[Paper]</a> <a href="https://github.com/google/bband-adaband">[Code]</a>
                            </li>



                            </ul>

                        </div>

            </div>



            <div class="section-title" style="margin-bottom: 20px">
                <h2>Workshop Paper</h2>
                    </div>
<!--                    <div class="section-title" style="margin-bottom: 10px">-->
<!--                        <h3>-->
<!--                            <font size="4"> 2024</font>-->
<!--                        </h3>-->
<!--                    </div>-->
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <ul>

                            <li>C. He, Q. Zheng, R. Zhu, X. Zeng, Y. Fan, Z. Tu,

                            <br> <b style="color:rgb(71, 71, 71)">"COVER: A comprehensive video quality evaluator"</b>
                                <br>IEEE/CVF Computer Vision and Pattern Recognition (CVPR) Workshops, 2024.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/He_COVER_A_Comprehensive_Video_Quality_Evaluator_CVPRW_2024_paper.html">[Paper]</a> <a href="https://github.com/vztu/COVER">[Code]</a>
                                <br><b><font color="red">🏆 1st place solution for <a href="https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Conde_AIS_2024_Challenge_on_Video_Quality_Assessment_of_User-Generated_Content_CVPRW_2024_paper.html">AIS 2024 UGC Video Quality Assessment Challenge</a></font></b>
                                    <br><b><font color="red">3rd place solution for <a href="https://arxiv.org/abs/2408.11982">AIM 2024 Challenge on Compressed Video Quality Assessment</a></font></b>

                            </li>



                            <li>X. Yu, Z. Tu, Z. Ying, A.C. Bovik, N. Birkbeck, Y. Wang, B. Adsumilli

                            <br> <b style="color:rgb(71, 71, 71)">"Subjective quality assessment of user-generated content gaming videos"</b>
                                <br>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops, 2022.
<!--                                <a href="https://mobility-lab.seas.ucla.edu/v2v4real/">[Project]</a>-->
                                <a href="https://openaccess.thecvf.com/content/WACV2022W/VAQ/html/Yu_Subjective_Quality_Assessment_of_User-Generated_Content_Gaming_Videos_WACVW_2022_paper.html">[Paper]</a> <a href="https://live.ece.utexas.edu/research/LIVE-YT-Gaming/index.html">[Dataset]</a>
                            </li>





                            </ul>
                </div>

            </div>

<!--         <div class="section-title" style="margin-bottom: 20px">-->
<!--                <h2>Patent</h2>-->
<!--                    </div>-->
<!--                    <div class="trend-entry d-flex">-->
<!--                        <div class="trend-contents">-->

<!--                             <ul>-->


<!--                           <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"Conditional Diffusion Models for Image Restoration"</b>-->
<!--                            </li>-->

<!--                                 <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"Laplacian Pyramid Network for Image Restoration"</b>-->
<!--                            </li>-->

<!--                                 <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"Multilayer Laplacian Resizer for Vision"</b>-->
<!--                            </li>-->

<!--                                 <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"Multi-Axis Vision Transformers"</b>-->
<!--                            </li>-->

<!--                                 <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"Multi-Axis MLP for Image Processing"</b>-->
<!--                            </li>-->

<!--                                 <li>-->
<!--                            <br> <b style="color:rgb(71, 71, 71)">"No-Reference Banding Artifact Predictor"</b>-->
<!--                            </li>-->

<!--                             </ul>-->

<!--                </div>-->

<!--            </div>-->

            <!-- END section -->
</div>

<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        &copy; <span id="current-year"></span> All rights reserved | Built upon
                        <a href="https://colorlib.com" target="_blank" rel="noopener noreferrer">Colorlib</a>
                    </p>
                    <!-- RevolverMaps Widget -->
                    <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=51rpu3e5zw4&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
                </div>
            </div>
        </div>
    </div>
</footer>

<script>
    document.getElementById('current-year').textContent = new Date().getFullYear();
</script>

        </div>
        <!-- .site-wrap -->


        <!-- loader -->
        <!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>

</div> -->

        <script src="js/jquery-3.3.1.min.js"></script>
        <script src="js/jquery-migrate-3.0.1.min.js"></script>
        <script src="js/jquery-ui.js"></script>
        <script src="js/popper.min.js"></script>
        <script src="js/bootstrap.min.js"></script>
        <script src="js/owl.carousel.min.js"></script>
        <script src="js/jquery.stellar.min.js"></script>
        <script src="js/jquery.countdown.min.js"></script>
        <script src="js/bootstrap-datepicker.min.js"></script>
        <script src="js/jquery.easing.1.3.js"></script>
        <script src="js/aos.js"></script>
        <script src="js/jquery.fancybox.min.js"></script>
        <script src="js/jquery.sticky.js"></script>
        <script src="js/jquery.mb.YTPlayer.min.js"></script>

        <script src="js/main.js"></script>

</body>

</html>