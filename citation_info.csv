,citing author name,citing paper title,cited paper title,affiliated institution,latitude,longitude,county,city,state,country
0,Ming-Hsuan Yang,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Merced,37.1641544,-120.7678602,Merced County,,California,United States
1,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
2,Liang Liao,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
3,Yonglin Tian,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
4,Vishnu Pandi Chellapandi,Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
5,Sandeep Mishra,Re-iqa: Unsupervised learning for image quality assessment in the wild,RAPIQUE: Rapid and accurate video quality prediction of user generated content,University of Texas at Austin,30.2851494,-97.73393515146053,Travis County,Austin,Texas,United States
6,Chaofeng Chen,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
7,Qi Zheng,COVER: A comprehensive video quality evaluator,BBAND Index: a No-Reference Banding Artifact Predictor,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
8,Xinlei Chen,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,FAIR,49.93216245,8.684753081266553,,Darmstadt,Hesse,Germany
9,Haoning Wu,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
10,Bonan Li,BlazeBVD: Make Scale-Time Equalization Great Again for Blind Video Deflickering,Pik-Fix: Restoring and Colorizing Old Photos,University of Chinese Academy of Sciences,39.907697049999996,116.24405770367915,,Shijingshan District,Beijing,China
11,Jiaqi Ma,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
12,Qi Zheng,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
13,Wei Dai,Vmaf and variants: Towards a unified vqa,Regression or classification? new methods to evaluate no-reference picture and video quality models,Hong Kong University of Science and Technology,22.3386304,114.2620337,,Sai Kung District,Hong Kong,China
14,Jiaqi Ma,HM-ViT: Hetero-modal vehicle-to-vehicle cooperative perception with vision transformer,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
15,Wenhui Wang,Image as a foreign language: Beit pretraining for vision and vision-language tasks,MaxViT: Multi-axis Vision Transformer,Microsoft Research,52.194951450000005,0.13501083507603753,Cambridgeshire,Cambridge,England,United Kingdom
16,David Bull,BVI-VFI: A video quality database for video frame interpolation,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,University of Bristol,51.4905582,-2.6304824978595356,North Somerset,,England,United Kingdom
17,Xiaojie Chu,Simple baselines for image restoration,MAXIM: Multi-Axis MLP for Image Processing,Apple,12.9822892,77.5962827,Bangalore North,Bengaluru,Karnataka,India
18,Dingkang Yang,How2comm: Communication-efficient and collaboration-pragmatic multi-agent perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
19,Yuzheng Wang,How2comm: Communication-efficient and collaboration-pragmatic multi-agent perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
20,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
21,Qiming Ai,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
22,Chaofeng Chen,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
23,Runsheng Xu,HM-ViT: Hetero-modal vehicle-to-vehicle cooperative perception with vision transformer,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
24,Li Wang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
25,Yue Hu,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
26,Xiangxu YU,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Adaptive debanding filter,Washington University in St. Louis,38.64724015,-90.30840174694748,Saint Louis County,St. Louis,Missouri,United States
27,Shunli Wang,"Aide: A vision-driven multi-view, multi-modal, multi-tasking dataset for assistive driving perception",V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
28,Xiongkuo Min (闵雄阔),A deep learning based no-reference quality assessment model for ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
29,Runsheng Xu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
30,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Kingston University,51.403073899999995,-0.3032181426130893,,London,England,United Kingdom
31,Qi Zheng,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
32,Christos G. Bampis,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
33,Yunsheng Ma,A survey on multimodal large language models for autonomous driving,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
34,Zhengzhong Tu,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
35,Wei Sun,Subjective and objective quality assessment for in-the-wild computer graphics images,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
36,Qi Zheng,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
37,Jingwen Hou,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
38,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,"Netflix, Los Gatos, CA, USA",37.25962235,-121.96267900730679,Santa Clara County,,California,United States
39,Junyu Dong,Curricular contrastive regularization for physics-aware single image dehazing,MAXIM: Multi-Axis MLP for Image Processing,Ocean University of China,36.072685050000004,120.42722436586305,,Laoshan District,Shandong,China
40,Wenxiu Sun,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,The Hong Kong University of Science and Technology,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
41,Yinan He,Vbench: Comprehensive benchmark suite for video generative models,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Al Laboratory,31.0847216,121.24852026398574,,Songjiang District,Shanghai,China
42,Joshua Peter Ebenezer,Subjective assessment of high dynamic range videos under different ambient conditions,BBAND Index: a No-Reference Banding Artifact Predictor,Samsung Research America,37.401170449999995,-122.04747512604908,Santa Clara County,Mountain View,California,United States
43,Peyman Milanfar,Maxvit: Multi-axis vision transformer,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Google,33.977092,-118.4092133,Los Angeles County,Los Angeles,California,United States
44,Jie Zhou,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MAXIM: Multi-Axis MLP for Image Processing,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
45,Zicheng Zhang,BH-VQA: Blind High Frame Rate Video Quality Assessment,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiaotong University,31.2143785,121.4680316,,Shanghai,Shanghai,China
46,Guangtao Zhai,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,Regression or classification? new methods to evaluate no-reference picture and video quality models,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
47,Soo Ye Kim,Modernizing old photos using multiple references via photorealistic style transfer,Pik-Fix: Restoring and Colorizing Old Photos,Adobe Research,47.5549905,7.5899398,,Basel,Basel-City,Switzerland
48,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,BBAND Index: a No-Reference Banding Artifact Predictor,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
49,Liangqi Yuan,Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
50,Jinjin GU,Dual aggregation transformer for image super-resolution,MaxViT: Multi-axis Vision Transformer,The University of Sydney,-33.88890725,151.18941110261173,,Sydney,New South Wales,Australia
51,Xu Cao,A survey on multimodal large language models for autonomous driving,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,UIUC,40.076154450000004,-88.22331340640494,Champaign County,Urbana,Illinois,United States
52,Yu Qiao,Activating more pixels in image super-resolution transformer,MAXIM: Multi-Axis MLP for Image Processing,CAS,5.5000085,-71.5000086,,,Casanare,Colombia
53,Agus Gunawan,Modernizing old photos using multiple references via photorealistic style transfer,Pik-Fix: Restoring and Colorizing Old Photos,Korea Advanced Institute of Science,36.3697191,127.36253700115094,,Daejeon,,South Korea
54,Zhengzhong Tu,Efficient user-generated video quality prediction,Regression or classification? new methods to evaluate no-reference picture and video quality models,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
55,Wei Sun,A deep learning based no-reference quality assessment model for ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
56,Jelena Vlaović,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,Asistent,45.0823089,25.3908339,Dâmbovița,,,Romania
57,Yongkai Huo,A viewport prediction framework for panoramic videos,Content adaptive tiling method based on user access preference for streaming panoramic video,University of Southampton,1.42991655,103.61217722346026,,Iskandar Puteri,Johor,Malaysia
58,Luka Murn,Lightweight Deep Exemplar Colorization via Semantic Attention-Guided Laplacian Pyramid,Pik-Fix: Restoring and Colorizing Old Photos,Nokia,51.2141598,4.4225738,Antwerp,Antwerp,Antwerp,Belgium
59,Jiangong Wang,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Institute of Automation,54.1720834,12.0790983,,Rostock,Mecklenburg-Vorpommern,Germany
60,Yansong Tang (唐彦嵩),Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MaxViT: Multi-axis Vision Transformer,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
61,Xin Xia,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
62,Yu-Chih Chen,GAMIVAL: Video quality prediction on mobile cloud gaming content,Subjective quality assessment of user-generated content gaming videos,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
63,Qi Zheng,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
64,Annan Wang,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
65,Li-Heng Chen,Learning to distort images using generative adversarial networks,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
66,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
67,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,The Hong Kong University of Science and Technology,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
68,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,The Hong Kong University of Science and Technology,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
69,Ziying Song,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
70,Avinab Saha,Re-iqa: Unsupervised learning for image quality assessment in the wild,RAPIQUE: Rapid and accurate video quality prediction of user generated content,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
71,Xiongkuo Min (闵雄阔),Deep learning based full-reference and no-reference quality assessment models for compressed ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
72,Liang Liao,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
73,Avinab Saha,Perceptual video quality assessment: The journey continues!,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
74,Chris Choy,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,NVIDIA,45.5344957,-122.886274,Washington County,Hillsboro,Oregon,United States
75,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Hebei University of Science,39.205429800000005,118.58595604901612,,Tangshan,Hebei,China
76,Xin Xia,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
77,Jiaqi Ma,HM-ViT: Hetero-modal vehicle-to-vehicle cooperative perception with vision transformer,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
78,Yanjun Huang 黄岩军,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Tongji University,31.27369175,121.38566174235456,,Putuo District,Shanghai,China
79,Li-Heng Chen,Learned fractional downsampling network for adaptive video streaming,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
80,Kai Wen Hu, Supporting Immersive Video Streaming via V2X Communication,Content adaptive tiling method based on user access preference for streaming panoramic video,National Dong Hwa University,23.8973249,121.5425779705339,Hualien County,,,Taiwan
81,Xiongkuo Min (闵雄阔),A deep learning based no-reference quality assessment model for ugc videos,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
82,Johan Bjorck,Image as a foreign language: Beit pretraining for vision and vision-language tasks,MaxViT: Multi-axis Vision Transformer,Cornell University,42.4529076,-76.48008423030923,Tompkins County,City of Ithaca,New York,United States
83,Tao Xiang,An end-to-end no-reference video quality assessment method with hierarchical spatiotemporal feature representation,Regression or classification? new methods to evaluate no-reference picture and video quality models,Chongqing University,29.5699826,106.4597701,,Shapingba District,Chongqing,China
84,Zhenqiang  Ying,Subjective and objective analysis of streamed gaming videos,Subjective quality assessment of user-generated content gaming videos,Inc.,38.321089,106.38857247478668,Lingwu City,Yinchuan City,Ningxia,China
85,Yixiang Mao,Progressive Frame Patching for FoV-based Point Cloud Video Streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,Computer Engineering,40.80803455,29.356343258075448,,,,Turkey
86,Zixing Lei,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
87,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,BBAND Index: a No-Reference Banding Artifact Predictor,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
88,Antonio Ortega,Rate-distortion optimization with alternative references for UGC video compression,Efficient user-generated video quality prediction,Computer Engineering,40.80803455,29.356343258075448,,,,Turkey
89,Hangwei Chen,Progressive Bidirectional Feature Extraction and Enhancement Network for Quality Evaluation of Night-Time Images,Subjective quality assessment of user-generated content gaming videos,Ningbo University,29.9091815,121.63348631338262,,Jiangbei District,Zhejiang,China
90,Xing Wen,"Zoom-vqa: Patches, frames and clips integration for video quality assessment",A comparative evaluation of temporal pooling methods for blind video quality assessment,Apple Inc.,37.3326452,-122.02992302100607,Santa Clara County,Cupertino,California,United States
91,Chen Zhao,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Institute of Automation,54.1720834,12.0790983,,Rostock,Mecklenburg-Vorpommern,Germany
92,Wenxiu Sun,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
93,Xiongkuo Min (闵雄阔),BH-VQA: Blind High Frame Rate Video Quality Assessment,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
94,Qi Zheng,Faver: Blind quality prediction of variable frame rate videos,BBAND Index: a No-Reference Banding Artifact Predictor,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
95,Alan Bovik,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
96,Ana Gavrovska,No-reference local image quality evaluation,Regression or classification? new methods to evaluate no-reference picture and video quality models,University of Belgrade,44.8179654,20.450776496755196,City of Belgrade,Belgrade,Central Serbia,Serbia
97,Zhi Li,Learning to distort images using generative adversarial networks,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
98,Yifan Lu,Collaboration helps camera overtake lidar in 3d detection,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
99,Anh T. Pham,An optimal tile-based approach for viewport-adaptive 360-degree video streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,University of Aizu,37.5236728,139.93807246412388,,Aizuwakamatsu,,Japan
100,Ligong Han,Svdiff: Compact parameter space for diffusion fine-tuning,MaxViT: Multi-axis Vision Transformer,Rutgers University,40.492977800000006,-74.44510808059266,Middlesex County,New Brunswick,New Jersey,United States
101,Yiming Li,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,NYU,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
102,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,"Netflix, Los Gatos, CA, USA",37.25962235,-121.96267900730679,Santa Clara County,,California,United States
103,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Wuhan University,30.537354049999998,114.36152031917142,,Wuchang District,Hubei,China
104,Alison Noble,A kernel density estimation based quality metric for quality assessment of obstetric ultrasound video,Adaptive debanding filter,UK,6.3110548,20.5447525,,,Ouaka,Central African Republic
105,Xiongkuo Min (闵雄阔),A deep learning based no-reference quality assessment model for ugc videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
106,Wei Lu,MD-VQA: Multi-dimensional quality assessment for UGC live videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
107,Min Hua,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of Birmingham,52.4522956,-1.9312856726008194,,Birmingham,England,United Kingdom
108,Yibo Fan,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
109,Daniel Y Fu,Hyena hierarchy: Towards larger convolutional language models,MaxViT: Multi-axis Vision Transformer,Stanford University,37.431313849999995,-122.16936535498309,Santa Clara County,,California,United States
110,Chia-Ju  Chen,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
111,Chaofeng Chen,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
112,Li Wang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
113,Wenliang Zhao,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MaxViT: Multi-axis Vision Transformer,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
114,Zhengzhong Tu,Efficient user-generated video quality prediction,Regression or classification? new methods to evaluate no-reference picture and video quality models,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
115,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
116,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
117,Chia-Ju  Chen,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
118,Walter Zimmer,Tumtraf v2x cooperative perception dataset,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Technical University of Munich (TUM),48.2655696,11.669345610437997,Landkreis München,,Bavaria,Germany
119,Guangtao Zhai,A deep learning based no-reference quality assessment model for ugc videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
120,Wei Sun,Analysis of video quality datasets via design of minimalistic video quality models,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
121,Rafal K. Mantiuk,Robust estimation of exposure ratios in multi-exposure image stacks,BBAND Index: a No-Reference Banding Artifact Predictor,University of Cambridge,52.210945550000005,0.09200497637871279,Cambridgeshire,Cambridge,England,United Kingdom
122,Erli Zhang,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
123,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
124,Wen Wang,Eva: Exploring the limits of masked visual representation learning at scale,MaxViT: Multi-axis Vision Transformer,Zhejiang University,30.521595,120.7195312,,Haining,Zhejiang,China
125,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
126,Wei Sun,Deep learning based full-reference and no-reference quality assessment models for compressed ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
127,Jingwen Hou,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
128,Congyan Lang,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
129,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,RAPIQUE: Rapid and accurate video quality prediction of user generated content,London,51.4893335,-0.14405508452768728,,London,England,United Kingdom
130,Zicheng Zhang,MD-VQA: Multi-dimensional quality assessment for UGC live videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,UTHealth,29.71215455,-95.3745266544489,Harris County,Houston,Texas,United States
131,Wei Sun,A deep learning based no-reference quality assessment model for ugc videos,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
132,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,H2O.ai,40.1858975,44.5073716,,Yerevan,,Armenia
133,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,Regression or classification? new methods to evaluate no-reference picture and video quality models,Wuhan University,30.537354049999998,114.36152031917142,,Wuchang District,Hubei,China
134,Hyeonjun Sim,Modernizing old photos using multiple references via photorealistic style transfer,Pik-Fix: Restoring and Colorizing Old Photos,Qualcomm,12.987455,77.7040726,Bangalore East,,Karnataka,India
135,Ruiyang Liu,Are we ready for a new paradigm shift? a survey on visual deep mlp,MAXIM: Multi-Axis MLP for Image Processing,清华大学,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
136,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Hebei University of Science,39.205429800000005,118.58595604901612,,Tangshan,Hebei,China
137,Yu-Chih Chen,Study of subjective and objective quality assessment of mobile cloud gaming videos,Subjective quality assessment of user-generated content gaming videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
138,Yang Liu,Spatio-temporal domain awareness for multi-agent collaborative perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of Toronto,43.663461999999996,-79.39775966248058,,Old Toronto,Ontario,Canada
139,Yansong Tang (唐彦嵩),Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MAXIM: Multi-Axis MLP for Image Processing,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
140,Snježana Rimac-Drlje,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,Faculty of Electrical Engineering,41.316834,19.82188934873777,Tirana County,Tirana,Central Albania,Albania
141,João Carreira,Attention-driven tile splitting method for improved efficiency of omnidirectional versatile video coding,Content adaptive tiling method based on user access preference for streaming panoramic video,Instituto de Telecomunicacoes,40.6340366,-8.659929522405761,Aveiro,Aveiro,,Portugal
142,Bernhard Jaeger,End-to-end autonomous driving: Challenges and frontiers,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of Tübingen,48.53405945,9.071244429234808,Landkreis Tübingen,,Baden-Württemberg,Germany
143,Shangchen Zhou,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
144,Li Dong,Image as a foreign language: Beit pretraining for vision and vision-language tasks,MaxViT: Multi-axis Vision Transformer,Microsoft Research,52.194951450000005,0.13501083507603753,Cambridgeshire,Cambridge,England,United Kingdom
145,Li-Heng Chen,Learning to distort images using generative adversarial networks,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
146,Jong Kwon,A kernel density estimation based quality metric for quality assessment of obstetric ultrasound video,Adaptive debanding filter,Oxford University,34.3653692,-89.5350279,Lafayette County,Oxford,Mississippi,United States
147,Weiwei Cai,Hierarchical damage correlations for old photo restoration,Pik-Fix: Restoring and Colorizing Old Photos,Jiangnan University,31.48512185,120.26733518229403,,Binhu District,Jiangsu,China
148,Zhenqiang  Ying,Patch-vq:'patching up'the video quality problem,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Inc.,38.321089,106.38857247478668,Lingwu City,Yinchuan City,Ningxia,China
149,Qi Zheng,COVER: A comprehensive video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
150,Shengfeng He,Hierarchical damage correlations for old photo restoration,Pik-Fix: Restoring and Colorizing Old Photos,Singapore Management University,1.29616795,103.85004365998248,,Singapore,,Singapore
151,Annan Wang,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
152,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Hebei University of Science and Technology,37.97742555,114.51560972019823,,Shijiazhuang,Hebei,China
153,Xuemin Hu,FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Hubei University,30.5796437,114.3234733,,Wuchang District,Hubei,China
154,Chongyi Li,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,Nankai University,39.101985,117.1609501175526,Nankai District,Nankai,Tianjin,China
155,Chaofeng Chen,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
156,Yang Zhou,A survey on multimodal large language models for autonomous driving,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,New York University,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
157,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
158,Ziqi Huang,Vbench: Comprehensive benchmark suite for video generative models,UGC-VQA: Benchmarking blind video quality assessment for user generated content,NTU,25.01688615,121.53852099555085,,Taipei,,Taiwan
159,Tu Danyang,MD-VQA: Multi-dimensional quality assessment for UGC live videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
160,"M. Emre Celebi, SPIE Fellow","Forty years of color quantization: a modern, algorithmic survey",Adaptive debanding filter,Engineering,14.6683641,120.994608,,Malabon,,Philippines
161,Jinjin GU,Dual aggregation transformer for image super-resolution,MAXIM: Multi-Axis MLP for Image Processing,The University of Sydney,-33.88890725,151.18941110261173,,Sydney,New South Wales,Australia
162,Qi Zheng,Faver: Blind quality prediction of variable frame rate videos,BBAND Index: a No-Reference Banding Artifact Predictor,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
163,Long Xu,Progressive Bidirectional Feature Extraction and Enhancement Network for Quality Evaluation of Night-Time Images,Subjective quality assessment of user-generated content gaming videos,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
164,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
165,Yifan Lu,Collaboration helps camera overtake lidar in 3d detection,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,NVIDIA,45.5344957,-122.886274,Washington County,Hillsboro,Oregon,United States
166,Rafal K. Mantiuk,Robust estimation of exposure ratios in multi-exposure image stacks,BBAND Index: a No-Reference Banding Artifact Predictor,UK,6.3110548,20.5447525,,,Ouaka,Central African Republic
167,Zhengzhong Tu,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
168,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
169,Zhi Li,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
170,Li-Heng Chen,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
171,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
172,Huifang Li,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Wuhan University,30.537354049999998,114.36152031917142,,Wuchang District,Hubei,China
173,Zhengzhong Tu,Maxim: Multi-axis mlp for image processing,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
174,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
175,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
176,Huifang Li,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Wuhan University,30.537354049999998,114.36152031917142,,Wuchang District,Hubei,China
177,Annan Wang,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
178,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
179,Haoning Wu,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
180,Qiu Bo,Study of subjective and objective quality assessment of mobile cloud gaming videos,Subjective quality assessment of user-generated content gaming videos,MIT,42.3582529,-71.0966272383055,Middlesex County,Cambridge,Massachusetts,United States
181,Qiu Bo,GAMIVAL: Video quality prediction on mobile cloud gaming content,Subjective quality assessment of user-generated content gaming videos,MIT,42.3582529,-71.0966272383055,Middlesex County,Cambridge,Massachusetts,United States
182,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
183,Qi Zheng,COVER: A comprehensive video quality evaluator,Subjective quality assessment of user-generated content gaming videos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
184,Wei Dai,Video Quality Analysis: Steps towards Unifying Full and No Reference Cases,Regression or classification? new methods to evaluate no-reference picture and video quality models,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
185,Haoning Wu,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
186,Ziqi Huang,Vbench: Comprehensive benchmark suite for video generative models,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
187,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
188,Zhengzhong Tu,Maxim: Multi-axis mlp for image processing,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
189,Runsheng Xu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
190,Yibo Fan,Interlayer restoration deep neural network for scalable high efficiency video coding,Adaptive debanding filter,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
191,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
192,Haoning Wu,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
193,Alan Bovik,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
194,Shoubhik Debnath,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,Meta,3.5000086,-73.0000086,,,Meta,Colombia
195,Qi Zheng,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
196,Congyan Lang,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
197,Han Yu,Ai-empowered persuasive video generation: A survey,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
198,Jose M. Alvarez,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,NVIDIA,45.5344957,-122.886274,Washington County,Hillsboro,Oregon,United States
199,Chunle Guo,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,Nankai University,39.101985,117.1609501175526,Nankai District,Nankai,Tianjin,China
200,Yingjie Zhou,Subjective and objective quality assessment for in-the-wild computer graphics images,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
201,Dingkang Yang,Spatio-temporal domain awareness for multi-agent collaborative perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
202,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
203,Huaidong Zhang,Hierarchical damage correlations for old photo restoration,Pik-Fix: Restoring and Colorizing Old Photos,South China University of Technology,23.1549709,113.3422197,,Tianhe District,Guangdong Province,China
204,Yiqi Zhong,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Microsoft,37.3974949,-122.0842646,Santa Clara County,Mountain View,California,United States
205,Chia-Ju  Chen,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
206,Haoning Wu,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
207,Zicheng Zhang,BlazeBVD: Make Scale-Time Equalization Great Again for Blind Video Deflickering,Pik-Fix: Restoring and Colorizing Old Photos,University of Chinese  Academy of Sciences,39.907697049999996,116.24405770367915,,Shijingshan District,Beijing,China
208,Jelena Vlaović,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,računarstva i informacijskih tehnologija Osijek,45.5568101,18.6955045,Osijek-Baranja County,Osijek,,Croatia
209,Zixing Lei,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
210,Liang Liao,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
211,Weijia Jia,An end-to-end no-reference video quality assessment method with hierarchical spatiotemporal feature representation,Regression or classification? new methods to evaluate no-reference picture and video quality models,UIC,41.868922299999994,-87.64858476010119,Cook County,Chicago,Illinois,United States
212,Kun Yang,How2comm: Communication-efficient and collaboration-pragmatic multi-agent perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
213,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
214,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Kingston University,51.403073899999995,-0.3032181426130893,,London,England,United Kingdom
215,Jingwen Hou,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
216,Zhengzhong Tu,A comparative evaluation of temporal pooling methods for blind video quality assessment,BBAND Index: a No-Reference Banding Artifact Predictor,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
217,Andreja Samčović,No-reference local image quality evaluation,Regression or classification? new methods to evaluate no-reference picture and video quality models,University of Belgrade,44.8179654,20.450776496755196,City of Belgrade,Belgrade,Central Serbia,Serbia
218,Liang Liao,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
219,Deepti Ghadiyaram,Patch-vq:'patching up'the video quality problem,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Runway,37.78160545,-122.30951661984686,Alameda County,Alameda,California,United States
220,Wei Lu,BH-VQA: Blind High Frame Rate Video Quality Assessment,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
221,Kun Yang,Spatio-temporal domain awareness for multi-agent collaborative perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
222,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Adaptive debanding filter,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
223,Huaidong Zhang,Delving into Important Samples of Semi-Supervised Old Photo Restoration: A New Dataset and Method,Pik-Fix: Restoring and Colorizing Old Photos,South China University of Technology,23.1549709,113.3422197,,Tianhe District,Guangdong Province,China
224,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Adaptive debanding filter,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
225,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Adaptive debanding filter,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
226,Kashyap Chitta,End-to-end autonomous driving: Challenges and frontiers,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of Tübingen,48.53405945,9.071244429234808,Landkreis Tübingen,,Baden-Württemberg,Germany
227,Xin Xia,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
228,Hai-Tao Zheng (郑海涛),Are we ready for a new paradigm shift? a survey on visual deep mlp,MAXIM: Multi-Axis MLP for Image Processing,Peng Cheng Laboratory,22.5751276,113.9383373,,Nanshan District,Guangdong Province,China
229,Nancy Mehta,The ninth NTIRE 2024 efficient super-resolution challenge report,MAXIM: Multi-Axis MLP for Image Processing,JMU Wuerzburg,49.780603150000005,9.971655766351642,,Würzburg,Bavaria,Germany
230,Xiongkuo Min (闵雄阔),Analysis of video quality datasets via design of minimalistic video quality models,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
231,Qi Zheng,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
232,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
233,Qi Zheng,COVER: A comprehensive video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
234,Erli Zhang,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
235,Christopher G. Brinton,Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
236,Shiqi Wang 王诗淇,Exploiting Bidirectional Quality Impulse for Reference Picture Resampled Gaming Video Coding,Subjective quality assessment of user-generated content gaming videos,City University of Hong Kong,22.3400204,114.16971664362887,,Kowloon,Hong Kong,China
237,Ghyslain Gagnon,No-reference video quality assessment using distortion learning and temporal attention,Efficient user-generated video quality prediction,Ecole de technologie supérieure,45.49451545,-73.5628554929944,Urban agglomeration of Montreal,Montreal,Quebec,Canada
238,Weijia Jia,An end-to-end no-reference video quality assessment method with hierarchical spatiotemporal feature representation,Regression or classification? new methods to evaluate no-reference picture and video quality models,Beijing Normal University,39.959732,116.35973697755406,,Xicheng District,Beijing,China
239,Zhengzhong Tu,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
240,Jiaqi Ma,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
241,Liang Liao,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
242,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
243,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Sony PlayStation,42.4621785,21.4740782,,Gjilan,,Kosovo
244,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
245,Jiantao Zhou,Activating more pixels in image super-resolution transformer,MAXIM: Multi-Axis MLP for Image Processing,Information Science,41.4823214,-72.4986995,Lower Connecticut River Valley Planning Region,,,United States
246,Qi Zheng,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
247,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
248,Linghe Kong,Dual aggregation transformer for image super-resolution,MaxViT: Multi-axis Vision Transformer,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
249,Wei Dai,Video Quality Analysis: Steps towards Unifying Full and No Reference Cases,Regression or classification? new methods to evaluate no-reference picture and video quality models,Hong Kong University of Science and Technology,22.3386304,114.2620337,,Sai Kung District,Hong Kong,China
250,Wei Sun,MD-VQA: Multi-dimensional quality assessment for UGC live videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
251,Xinlei Chen,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,"FAIR, Meta",4.3129074,-72.0784394,,,Meta,Colombia
252,Zhengzhong Tu,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
253,Xiangxu YU,Subjective and objective analysis of streamed gaming videos,Subjective quality assessment of user-generated content gaming videos,Washington University in St. Louis,38.64724015,-90.30840174694748,Saint Louis County,St. Louis,Missouri,United States
254,Chaowei Xiao,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of Wisconsin - Madison,43.080274450000005,-89.43095871991434,Dane County,,Wisconsin,United States
255,Haoning Wu,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
256,Guangtao Zhai,Analysis of video quality datasets via design of minimalistic video quality models,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
257,Chunyi Li,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
258,Jianmin Jiang,A viewport prediction framework for panoramic videos,Content adaptive tiling method based on user access preference for streaming panoramic video,Shenzhen University,22.53590225,113.93147487492186,,Nanshan District,Guangdong Province,China
259,Yawei Li,Efficient and explicit modelling of image hierarchies for image restoration,MAXIM: Multi-Axis MLP for Image Processing,ETH Zurich,47.413218,8.5374914,District Zurich,Zurich,Zurich,Switzerland
260,Karoll Quijano,YOLOv5-Tassel: Detecting tassels in RGB UAV imagery with improved YOLOv5 based on transfer learning,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
261,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
262,Haoning Wu,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
263,Nisar Ahmed,TQP: An Efficient Video Quality Assessment Framework for Adaptive Bitrate Video Streaming,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Technology Lahore,31.5015016,74.332101,,Lahore,Punjab,Pakistan
264,Runsheng Xu,Collaboration helps camera overtake lidar in 3d detection,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
265,Jiaqi Ma,HM-ViT: Hetero-modal vehicle-to-vehicle cooperative perception with vision transformer,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
266,Weiwei Cai,Delving into Important Samples of Semi-Supervised Old Photo Restoration: A New Dataset and Method,Pik-Fix: Restoring and Colorizing Old Photos,Jiangnan University,31.48512185,120.26733518229403,,Binhu District,Jiangsu,China
267,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
268,Lei Zhu,Biformer: Vision transformer with bi-level routing attention,MaxViT: Multi-axis Vision Transformer,City University of Hong Kong,22.3400204,114.16971664362887,,Kowloon,Hong Kong,China
269,Haoning Wu,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
270,Agus Gunawan,Modernizing old photos using multiple references via photorealistic style transfer,Pik-Fix: Restoring and Colorizing Old Photos,Technology (KAIST),36.3697191,127.36253700115094,,Daejeon,,South Korea
271,Yawei Li,The ninth NTIRE 2024 efficient super-resolution challenge report,MAXIM: Multi-Axis MLP for Image Processing,ETH Zurich,47.413218,8.5374914,District Zurich,Zurich,Zurich,Switzerland
272,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Hebei University of Science and Technology,37.97742555,114.51560972019823,,Shijiazhuang,Hebei,China
273,Zhengzhong Tu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
274,Ruicheng Feng,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
275,Qi Zheng,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
276,Zhengzhong Tu,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
277,Mingcheng Li,Spatio-temporal domain awareness for multi-agent collaborative perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
278,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
279,Wei Dai,Vmaf and variants: Towards a unified vqa,Regression or classification? new methods to evaluate no-reference picture and video quality models,Hong Kong University of Science,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
280,Zefeng Chen,Ai-generated content (aigc): A survey,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Jinan University,22.2518247,113.52912551084435,,Xiangzhou District,Guangdong Province,China
281,Louay Hazami, Efficientvdvae: Less is more,Adaptive debanding filter,Block Inc.,37.8089951,-122.2690215,Alameda County,Oakland,California,United States
282,Li-Heng Chen,Perceptual video quality prediction emphasizing chroma distortions,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
283,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,BBAND Index: a No-Reference Banding Artifact Predictor,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
284,Huyen T. T. Tran,An optimal tile-based approach for viewport-adaptive 360-degree video streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,RIKEN,47.2760208,7.8491956,Bezirk Zofingen,,Aargau,Switzerland
285,Liang Liao,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
286,Yixiang Mao,Progressive Frame Patching for FoV-based Point Cloud Video Streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,New York University,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
287,Weiwei Cai,Delving into Important Samples of Semi-Supervised Old Photo Restoration: A New Dataset and Method,Pik-Fix: Restoring and Colorizing Old Photos,Northern Arizona University,35.1834428,-111.65500037883243,Coconino County,Flagstaff,Arizona,United States
288,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix,48.8712345,2.3288752,,Paris,Ile-de-France,France
289,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,The Hong Kong University of Science,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
290,Zheng Chen,Dual aggregation transformer for image super-resolution,MAXIM: Multi-Axis MLP for Image Processing,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
291,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
292,Yulun Zhang,Dual aggregation transformer for image super-resolution,MaxViT: Multi-axis Vision Transformer,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
293,Guangtao Zhai,A deep learning based no-reference quality assessment model for ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
294,Chenn-Jung Huang, Supporting Immersive Video Streaming via V2X Communication,Content adaptive tiling method based on user access preference for streaming panoramic video,National Dong Hwa University,23.8973249,121.5425779705339,Hualien County,,,Taiwan
295,Ziying Song,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
296,Wei Sun,BH-VQA: Blind High Frame Rate Video Quality Assessment,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
297,Qi Zheng,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
298,Long Chen,FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
299,Jie LEI,Interlayer restoration deep neural network for scalable high efficiency video coding,Adaptive debanding filter,University of Technology Sydney,-33.88325365,151.20032937174193,,Sydney,New South Wales,Australia
300,Peyman Milanfar,Svdiff: Compact parameter space for diffusion fine-tuning,MaxViT: Multi-axis Vision Transformer,Google,33.977092,-118.4092133,Los Angeles County,Los Angeles,California,United States
301,Avinab Saha,GAMIVAL: Video quality prediction on mobile cloud gaming content,Subjective quality assessment of user-generated content gaming videos,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
302,Christos G. Bampis,Learned fractional downsampling network for adaptive video streaming,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
303,Xiangxu YU,RAPIQUE: Rapid and accurate video quality prediction of user generated content,A comparative evaluation of temporal pooling methods for blind video quality assessment,Washington University in St. Louis,38.64724015,-90.30840174694748,Saint Louis County,St. Louis,Missouri,United States
304,Wenxiu Sun,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,The Hong Kong University of Science,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
305,Rafal K. Mantiuk,Robust estimation of exposure ratios in multi-exposure image stacks,BBAND Index: a No-Reference Banding Artifact Predictor,Displays,53.974367900000004,-8.987891843315612,County Mayo,,,Ireland
306,Guangtao Zhai,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
307,Qi Zheng,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
308,Haoning Wu,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
309,"Abbas Jamalipour, Fellow IEEE, Fellow IEICE, Fellow IEA","A Survey on Virtual Reality over Wireless Networks: Fundamentals, QoE, Enabling Technologies, Research Trends and Open Issues",Content adaptive tiling method based on user access preference for streaming panoramic video,The University of Sydney,-33.88890725,151.18941110261173,,Sydney,New South Wales,Australia
310,Wenqian Ye,A survey on multimodal large language models for autonomous driving,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of Virginia,38.0410576,-78.50550841214823,Albemarle County,Charlottesville,Virginia,United States
311,Zhengzhong Tu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
312,Zhi Li,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
313,Weiying Xie,Interlayer restoration deep neural network for scalable high efficiency video coding,Adaptive debanding filter,Xidian University,34.1251589,108.82896528504287,,Chang'an District,Shaanxi,China
314,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
315,Jelena Vlaović,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,Fakultet elektrotehnike,45.8008192,15.9710984020958,,City of Zagreb,,Croatia
316,Yansong Tang (唐彦嵩),Ada-dqa: Adaptive diverse quality-aware feature acquisition for video quality assessment,Efficient user-generated video quality prediction,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
317,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
318,Wenxiu Sun,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,The Hong Kong University of Science,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
319,Muhammad Azeem Aslam,TQP: An Efficient Video Quality Assessment Framework for Adaptive Bitrate Video Streaming,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Northwestern Polytechnical University,34.2469224,108.91062353292654,,Beilin District,Shaanxi,China
320,Meng Zonglin,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
321,Yulun Zhang,Dual aggregation transformer for image super-resolution,MAXIM: Multi-Axis MLP for Image Processing,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
322,Christos G. Bampis,Learning to distort images using generative adversarial networks,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
323,Zhengzhong Tu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
324,Luka Murn,Lightweight Deep Exemplar Colorization via Semantic Attention-Guided Laplacian Pyramid,Pik-Fix: Restoring and Colorizing Old Photos,Dublin City University,53.386489499999996,-6.25926073106762,County Dublin,Dublin,,Ireland
325,Runsheng Xu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
326,Qi Zheng,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
327,Zhiyun Deng,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
328,Jingwen Hou,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
329,Sai Karthikey  Pentapati,Perceptual video quality assessment: The journey continues!,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,University of Texas at Austin,30.2851494,-97.73393515146053,Travis County,Austin,Texas,United States
330,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
331,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,The Hong Kong University of Science,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
332,Sai Karthikey  Pentapati,Perceptual video quality assessment: The journey continues!,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
333,Shaoheng Fang,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,UT Austin,30.284458,-97.7342106,Travis County,Austin,Texas,United States
334,Liang Liao,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
335,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
336,Chia-Ju  Chen,Efficient user-generated video quality prediction,Regression or classification? new methods to evaluate no-reference picture and video quality models,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
337,Alan Bovik,Subjective assessment of high dynamic range videos under different ambient conditions,BBAND Index: a No-Reference Banding Artifact Predictor,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
338,Mading Li,Quality-aware pre-trained models for blind image quality assessment,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Peking University,40.17336535,116.15722001868669,,Changping District,Beijing,China
339,Wayne Zhang,Biformer: Vision transformer with bi-level routing attention,MaxViT: Multi-axis Vision Transformer,The Chinese University of Hong Kong,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
340,Denis Demandolx,Efficient and explicit modelling of image hierarchies for image restoration,MAXIM: Multi-Axis MLP for Image Processing,Meta,3.5000086,-73.0000086,,,Meta,Colombia
341,Christos G. Bampis,Learning to distort images using generative adversarial networks,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
342,Hong Lin,Ai-generated content (aigc): A survey,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Jinan University,22.2518247,113.52912551084435,,Xiangzhou District,Guangdong Province,China
343,Meng Zonglin,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
344,Mu Li,Modular Blind Video Quality Assessment,Subjective quality assessment of user-generated content gaming videos,Sydney University,-33.88890725,151.18941110261173,,Sydney,New South Wales,Australia
345,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Adaptive debanding filter,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
346,"Md. Farhad Hossain, PhD","A Survey on Virtual Reality over Wireless Networks: Fundamentals, QoE, Enabling Technologies, Research Trends and Open Issues",Content adaptive tiling method based on user access preference for streaming panoramic video,Professor,59.8902797,11.857567,Innlandet,,,Norway
347,Yue Hu,Collaboration helps camera overtake lidar in 3d detection,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
348,Dr. Arslan Ahmad,"Measuring, modeling and integrating time-varying video quality in end-to-end multimedia service delivery: A review and open challenges",A comparative evaluation of temporal pooling methods for blind video quality assessment,Cardiff Metropolitan University,51.4960947,-3.2127615385866655,Cardiff,Cardiff,Wales,United Kingdom
349,Wei Lu,A deep learning based no-reference quality assessment model for ugc videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
350,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
351,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Netflix,48.8712345,2.3288752,,Paris,Ile-de-France,France
352,Nisar Ahmed,TQP: An Efficient Video Quality Assessment Framework for Adaptive Bitrate Video Streaming,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,University of Engineering,12.90806315,80.14014108509298,Tambaram,,Tamil Nadu,India
353,Qi Zheng,COVER: A comprehensive video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
354,Qi Zheng,COVER: A comprehensive video quality evaluator,Subjective quality assessment of user-generated content gaming videos,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
355,Yu-Chih Chen,GAMIVAL: Video quality prediction on mobile cloud gaming content,Subjective quality assessment of user-generated content gaming videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
356,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
357,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
358,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
359,Zhengzhong Tu,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
360,Zhengzhong Tu,Faver: Blind quality prediction of variable frame rate videos,BBAND Index: a No-Reference Banding Artifact Predictor,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
361,Jiaqi Ma,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
362,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
363,Guangtao Zhai,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,A comparative evaluation of temporal pooling methods for blind video quality assessment,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
364,Ming-Hsuan Yang,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Merced,37.1641544,-120.7678602,Merced County,,California,United States
365,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,Regression or classification? new methods to evaluate no-reference picture and video quality models,Electronic Information School,34.3825551,108.98153887655354,,Weiyang District,Shaanxi,China
366,Hongyuan Yu 俞宏远,The ninth NTIRE 2024 efficient super-resolution challenge report,MAXIM: Multi-Axis MLP for Image Processing,CASIA,25.7491889,-100.148685,,Apodaca,Nuevo León,Mexico
367,Geng Yuan,Efficientformer: Vision transformers at mobilenet speed,MaxViT: Multi-axis Vision Transformer,University of Georgia,33.9404278,-83.37304904988295,Athens-Clarke County,Athens-Clarke County Unified Government,Georgia,United States
368,Christos G. Bampis,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
369,Wenxiu Sun,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
370,Zhengzhong Tu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
371,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,A comparative evaluation of temporal pooling methods for blind video quality assessment,Wuhan University,30.537354049999998,114.36152031917142,,Wuchang District,Hubei,China
372,Jingwen Hou,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
373,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Kingston University,51.403073899999995,-0.3032181426130893,,London,England,United Kingdom
374,Zhengzhong Tu,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
375,Chaofeng Chen,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
376,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Sony PlayStation,42.4621785,21.4740782,,Gjilan,,Kosovo
377,Zhi Li,Learning to distort images using generative adversarial networks,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
378,Dingkang Yang,"Aide: A vision-driven multi-view, multi-modal, multi-tasking dataset for assistive driving perception",V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
379,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,The Hong Kong University of Science,22.4201838,114.20791453524086,,Sha Tin District,Hong Kong,China
380,Wei Sun,A deep learning based no-reference quality assessment model for ugc videos,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
381,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,A comparative evaluation of temporal pooling methods for blind video quality assessment,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
382,Zhengzhong Tu,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
383,Sandeep Mishra,Re-iqa: Unsupervised learning for image quality assessment in the wild,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
384,Eric Nguyen,Hyena hierarchy: Towards larger convolutional language models,MaxViT: Multi-axis Vision Transformer,Stanford University,37.431313849999995,-122.16936535498309,Santa Clara County,,California,United States
385,Zhanghan Ke,Biformer: Vision transformer with bi-level routing attention,MaxViT: Multi-axis Vision Transformer,City University of Hong Kong,22.3400204,114.16971664362887,,Kowloon,Hong Kong,China
386,Ju Hu,Efficientformer: Vision transformers at mobilenet speed,MaxViT: Multi-axis Vision Transformer,Snap Inc.,33.988216050000005,-118.47329061789004,Los Angeles County,Los Angeles,California,United States
387,Jingwen Hou,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
388,Weiwei Cai,Hierarchical damage correlations for old photo restoration,Pik-Fix: Restoring and Colorizing Old Photos,Northern Arizona University,35.1834428,-111.65500037883243,Coconino County,Flagstaff,Arizona,United States
389,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Sony PlayStation,42.4621785,21.4740782,,Gjilan,,Kosovo
390,Andreas Geiger,End-to-end autonomous driving: Challenges and frontiers,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of Tübingen,48.53405945,9.071244429234808,Landkreis Tübingen,,Baden-Württemberg,Germany
391,Peyman Milanfar,Maxvit: Multi-axis vision transformer,MAXIM: Multi-Axis MLP for Image Processing,Google,33.977092,-118.4092133,Los Angeles County,Los Angeles,California,United States
392,Vishnu Pandi Chellapandi,Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Research,-37.7066557,145.189067,,Melbourne,Victoria,Australia
393,Jiangong Wang,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
394,Xiongkuo Min (闵雄阔),A deep learning based no-reference quality assessment model for ugc videos,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
395,Avinab Saha,GAMIVAL: Video quality prediction on mobile cloud gaming content,Subjective quality assessment of user-generated content gaming videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
396,Guangtao Zhai,A deep learning based no-reference quality assessment model for ugc videos,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
397,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
398,Michael Poli,Hyena hierarchy: Towards larger convolutional language models,MaxViT: Multi-axis Vision Transformer,Stanford University,37.431313849999995,-122.16936535498309,Santa Clara County,,California,United States
399,Lingxi Li,FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
400,Christos G. Bampis,Perceptual video quality prediction emphasizing chroma distortions,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
401,Chia-Ju  Chen,Efficient user-generated video quality prediction,Regression or classification? new methods to evaluate no-reference picture and video quality models,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
402,Runsheng Xu,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
403,Avinab Saha,Study of subjective and objective quality assessment of mobile cloud gaming videos,Subjective quality assessment of user-generated content gaming videos,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
404,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,BBAND Index: a No-Reference Banding Artifact Predictor,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
405,Zicheng Zhang,Subjective and objective quality assessment for in-the-wild computer graphics images,Subjective quality assessment of user-generated content gaming videos,UTHealth,29.71215455,-95.3745266544489,Harris County,Houston,Texas,United States
406,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Los Gatos,37.226611,-121.9746797,Santa Clara County,,California,United States
407,Yu-Chih Chen,Study of subjective and objective quality assessment of mobile cloud gaming videos,Subjective quality assessment of user-generated content gaming videos,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
408,Suren Sritharan,Tumtraf v2x cooperative perception dataset,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Technische Universität München,48.14907275,11.567444920339295,,Munich,Bavaria,Germany
409,Congying Han,BlazeBVD: Make Scale-Time Equalization Great Again for Blind Video Deflickering,Pik-Fix: Restoring and Colorizing Old Photos,University of Chinese Academy of Sciences,39.907697049999996,116.24405770367915,,Shijingshan District,Beijing,China
410,Yonglin Tian,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Institute of Automation,54.1720834,12.0790983,,Rostock,Mecklenburg-Vorpommern,Germany
411,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
412,Eduardo Pavez,Rate-distortion optimization with alternative references for UGC video compression,Efficient user-generated video quality prediction,University of Southern California,34.02186895,-118.285857923125,Los Angeles County,Los Angeles,California,United States
413,Karoll Quijano,YOLOv5-Tassel: Detecting tassels in RGB UAV imagery with improved YOLOv5 based on transfer learning,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
414,Xiangxu YU,RAPIQUE: Rapid and accurate video quality prediction of user generated content,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Washington University in St. Louis,38.64724015,-90.30840174694748,Saint Louis County,St. Louis,Missouri,United States
415,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
416,Chaofeng Chen,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
417,Weidi Xie,Collaboration helps camera overtake lidar in 3d detection,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of Oxford,51.75870755,-1.2556684826092037,Oxfordshire,Oxford,England,United Kingdom
418,Peyman Milanfar,Maxvit: Multi-axis vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Google,33.977092,-118.4092133,Los Angeles County,Los Angeles,California,United States
419,Avinab Saha,Perceptual video quality assessment: The journey continues!,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
420,Daniel Joseph Ringis, Re-Engineering Rate Distortion Optimisation in Modern Video Codecs Using a Per Clip Approach,Efficient user-generated video quality prediction,The University of the West Indies,13.0988619,-59.58139521254482,Saint Michael,,,Barbados
421,Zhiyun Deng,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
422,Long Xu,Progressive Bidirectional Feature Extraction and Enhancement Network for Quality Evaluation of Night-Time Images,Subjective quality assessment of user-generated content gaming videos,Peng Cheng Laboratory,22.5751276,113.9383373,,Nanshan District,Guangdong Province,China
423,Qi Zheng,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
424,Shaoheng Fang,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,UT Austin,30.284458,-97.7342106,Travis County,Austin,Texas,United States
425,Can Cui,A survey on multimodal large language models for autonomous driving,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Purdue University,40.430028,-86.92642114650494,Tippecanoe County,West Lafayette,Indiana,United States
426,Sérgio M. M. de Faria,Attention-driven tile splitting method for improved efficiency of omnidirectional versatile video coding,Content adaptive tiling method based on user access preference for streaming panoramic video,Instituto de Telecomunicações,40.6340366,-8.659929522405761,Aveiro,Aveiro,,Portugal
427,Qi Zheng,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
428,João Carreira,Attention-driven tile splitting method for improved efficiency of omnidirectional versatile video coding,Content adaptive tiling method based on user access preference for streaming panoramic video,Instituto Politécnico de Leiria,39.73729325,-8.811333913163399,Leiria,Leiria,,Portugal
429,"Kumudu Munasinghe, PhD","A Survey on Virtual Reality over Wireless Networks: Fundamentals, QoE, Enabling Technologies, Research Trends and Open Issues",Content adaptive tiling method based on user access preference for streaming panoramic video,University of Canberra,-35.2365904,149.08450971975765,,,,Australia
430,Chaofeng Chen,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
431,Chia-Ju  Chen,Efficient user-generated video quality prediction,Regression or classification? new methods to evaluate no-reference picture and video quality models,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
432,Yue Hu,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
433,Jingyu Zhang,Spatio-temporal domain awareness for multi-agent collaborative perception,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
434,Hangbo Bao,Image as a foreign language: Beit pretraining for vision and vision-language tasks,MaxViT: Multi-axis Vision Transformer,Microsoft Research,52.194951450000005,0.13501083507603753,Cambridgeshire,Cambridge,England,United Kingdom
435,Zhengzhong Tu,A completely blind video quality evaluator,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
436,Duc Nguyen,An optimal tile-based approach for viewport-adaptive 360-degree video streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,Tohoku Institute of Technology,38.246111400000004,140.85312066240687,,Sendai,,Japan
437,Wei Lu,A deep learning based no-reference quality assessment model for ugc videos,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
438,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
439,Xin Xiong,Rate-distortion optimization with alternative references for UGC video compression,Efficient user-generated video quality prediction,University of Southern California,34.02186895,-118.285857923125,Los Angeles County,Los Angeles,California,United States
440,Zhengzhong Tu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
441,Hai-Tao Zheng (郑海涛),Are we ready for a new paradigm shift? a survey on visual deep mlp,MAXIM: Multi-Axis MLP for Image Processing,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
442,Zhi Li,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
443,Jose M. Alvarez,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,NVIDIA,45.5344957,-122.886274,Washington County,Hillsboro,Oregon,United States
444,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
445,Li Xu,Interlayer restoration deep neural network for scalable high efficiency video coding,Adaptive debanding filter,CEO,42.3436021,-8.4427896,Vigo,,Galicia,Spain
446,Min Hua,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of Birmingham,52.4522956,-1.9312856726008194,,Birmingham,England,United Kingdom
447,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
448,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,London,51.4893335,-0.14405508452768728,,London,England,United Kingdom
449,Linghe Kong,Dual aggregation transformer for image super-resolution,MAXIM: Multi-Axis MLP for Image Processing,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
450,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,A comparative evaluation of temporal pooling methods for blind video quality assessment,Electronic Information School,34.3825551,108.98153887655354,,Weiyang District,Shaanxi,China
451,Li-Heng Chen,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
452,Alan Bovik,Re-iqa: Unsupervised learning for image quality assessment in the wild,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
453,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
454,Erli Zhang,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
455,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,A comparative evaluation of temporal pooling methods for blind video quality assessment,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
456,Drago Žagar,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,Faculty of Electrical Engineering,41.316834,19.82188934873777,Tirana County,Tirana,Central Albania,Albania
457,Xin Xia,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
458,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
459,Zhi Li,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
460,Joshua Peter Ebenezer,ChipQA: No-reference video quality prediction via space-time chips,A comparative evaluation of temporal pooling methods for blind video quality assessment,Samsung Research America,37.401170449999995,-122.04747512604908,Santa Clara County,Mountain View,California,United States
461,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
462,Hai Wei,ChipQA: No-reference video quality prediction via space-time chips,A comparative evaluation of temporal pooling methods for blind video quality assessment,Amazon,-3.1883219,-59.5174371,,,Amazonas,Brazil
463,Yu Qiao,Activating more pixels in image super-resolution transformer,MAXIM: Multi-Axis MLP for Image Processing,Shenzhen Institutes of Advanced Technology,22.598056049999997,113.98533784139858,,Nanshan District,Guangdong Province,China
464,Chaofeng Chen,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,RAPIQUE: Rapid and accurate video quality prediction of user generated content,S-Lab,54.7391503,55.9709483,городской округ Уфа,Ufa,Bashkortostan,Russia
465,Chaofeng Chen,Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
466,Fan Zhang,BVI-VFI: A video quality database for video frame interpolation,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,University of Bristol,51.4905582,-2.6304824978595356,North Somerset,,England,United Kingdom
467,Meng Zonglin,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
468,Andrey Norkin,ProxIQA: A proxy approach to perceptual optimization of learned image compression,Adaptive debanding filter,Los Gatos,37.226611,-121.9746797,Santa Clara County,,California,United States
469,Zhi Li,Learning to distort images using generative adversarial networks,Adaptive debanding filter,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
470,Weixia Zhang,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
471,Chaminda Thushara Hewage,"Measuring, modeling and integrating time-varying video quality in end-to-end multimedia service delivery: A review and open challenges",A comparative evaluation of temporal pooling methods for blind video quality assessment,Cardiff Metropolitan University,51.4960947,-3.2127615385866655,Cardiff,Cardiff,Wales,United Kingdom
472,Chaowei Xiao,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,University of Wisconsin - Madison,43.080274450000005,-89.43095871991434,Dane County,,Wisconsin,United States
473,Zheng Chen,Dual aggregation transformer for image super-resolution,MaxViT: Multi-axis Vision Transformer,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
474,Qi Zheng,COVER: A comprehensive video quality evaluator,BBAND Index: a No-Reference Banding Artifact Predictor,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
475,Zhengzhong Tu,No-reference quality assessment of variable frame-rate videos using temporal bandpass statistics,Regression or classification? new methods to evaluate no-reference picture and video quality models,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
476,Zhengzhong Tu,A completely blind video quality evaluator,Pik-Fix: Restoring and Colorizing Old Photos,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
477,Guoxin Zhang,Multi-modal 3d object detection in autonomous driving: A survey and taxonomy,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
478,Ronghang Hu,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,Meta,3.5000086,-73.0000086,,,Meta,Colombia
479,Tu Danyang,BH-VQA: Blind High Frame Rate Video Quality Assessment,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
480,Zicheng Zhang,Subjective and objective quality assessment for in-the-wild computer graphics images,Subjective quality assessment of user-generated content gaming videos,Shanghai Jiaotong University,31.2143785,121.4680316,,Shanghai,Shanghai,China
481,Qi Zheng,COVER: A comprehensive video quality evaluator,BBAND Index: a No-Reference Banding Artifact Predictor,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
482,Li Xu,Interlayer restoration deep neural network for scalable high efficiency video coding,Adaptive debanding filter,Xidian University,34.1251589,108.82896528504287,,Chang'an District,Shaanxi,China
483,Yi Jin,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
484,Xinlei Chen,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,Meta,3.5000086,-73.0000086,,,Meta,Colombia
485,Haoxin YANG,Hierarchical damage correlations for old photo restoration,Pik-Fix: Restoring and Colorizing Old Photos,South China University of Technology,23.1549709,113.3422197,,Tianhe District,Guangdong Province,China
486,Jiantao Zhou,Activating more pixels in image super-resolution transformer,MAXIM: Multi-Axis MLP for Image Processing,University of Macau,22.1283648,113.543778397594,,,Macau,China
487,Zhengzhong Tu,Faver: Blind quality prediction of variable frame rate videos,BBAND Index: a No-Reference Banding Artifact Predictor,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
488,Yiqi Zhong,Where2comm: Communication-efficient collaborative perception via spatial confidence maps,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Microsoft,37.3974949,-122.0842646,Santa Clara County,Mountain View,California,United States
489,Avinab Saha,Re-iqa: Unsupervised learning for image quality assessment in the wild,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
490,Jie Zhou,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MaxViT: Multi-axis Vision Transformer,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
491,Stefano Massaroli,Hyena hierarchy: Towards larger convolutional language models,MaxViT: Multi-axis Vision Transformer,RIKEN,47.2760208,7.8491956,Bezirk Zofingen,,Aargau,Switzerland
492,Yunfeng Ai,FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,University of Chinese Academy of Sciences,39.907697049999996,116.24405770367915,,Shijingshan District,Beijing,China
493,Chen Zhao,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
494,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
495,Dr Nabajeet Barman,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,UGC-VQA: Benchmarking blind video quality assessment for user generated content,London,51.4893335,-0.14405508452768728,,London,England,United Kingdom
496,Yanjun Huang 黄岩军,A systematic survey of control techniques and applications in connected and automated vehicles,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Tongji University,31.27369175,121.38566174235456,,Putuo District,Shanghai,China
497,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,A comparative evaluation of temporal pooling methods for blind video quality assessment,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
498,Wenxiu Sun,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,The Hong Kong University of Science and Technology,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
499,Zhengzhong Tu,Maxvit: Multi-axis vision transformer,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
500,Shengfeng He,Curricular contrastive regularization for physics-aware single image dehazing,MAXIM: Multi-Axis MLP for Image Processing,Singapore Management University,1.29616795,103.85004365998248,,Singapore,,Singapore
501,Lingxi Li,FusionPlanner: A multi-task motion planner for mining trucks via multi-sensor fusion,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Computer Engineering,40.80803455,29.356343258075448,,,,Turkey
502,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,The Hong Kong University of Science and Technology,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
503,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,RAPIQUE: Rapid and accurate video quality prediction of user generated content,H2O.ai,40.1858975,44.5073716,,Yerevan,,Armenia
504,Thanuja Mallikarachchi,"Measuring, modeling and integrating time-varying video quality in end-to-end multimedia service delivery: A review and open challenges",A comparative evaluation of temporal pooling methods for blind video quality assessment,Cardiff Metropolitan University,51.4960947,-3.2127615385866655,Cardiff,Cardiff,Wales,United Kingdom
505,Yutong Wang,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Chinese Academy of Sciences,39.90933665,116.32971461228999,,Beijing,Beijing,China
506,Liang Liao,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
507,Xin Xia,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,"University of California, Los Angeles",34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
508,Qi Zheng,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai,31.2323437,121.4691024,,Shanghai,Shanghai,China
509,Runsheng Xu,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
510,Sérgio M. M. de Faria,Attention-driven tile splitting method for improved efficiency of omnidirectional versatile video coding,Content adaptive tiling method based on user access preference for streaming panoramic video,Instituto Politécnico de Leiria,39.73729325,-8.811333913163399,Leiria,Leiria,,Portugal
511,Qi Zheng,COVER: A comprehensive video quality evaluator,Subjective quality assessment of user-generated content gaming videos,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
512,Wei Dai,Video Quality Analysis: Steps towards Unifying Full and No Reference Cases,Regression or classification? new methods to evaluate no-reference picture and video quality models,Hong Kong University of Science,22.3358031,114.2659087549023,,Sai Kung District,Hong Kong,China
513,Zhi Li,Perceptual video quality prediction emphasizing chroma distortions,BBAND Index: a No-Reference Banding Artifact Predictor,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
514,Yuchen Fan,Efficient and explicit modelling of image hierarchies for image restoration,MAXIM: Multi-Axis MLP for Image Processing,University of Illinois,40.076154450000004,-88.22331340640494,Champaign County,Urbana,Illinois,United States
515,Jingwen Hou,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
516,Marcos V. Conde,AIS 2024 challenge on video quality assessment of user-generated content: Methods and results,UGC-VQA: Benchmarking blind video quality assessment for user generated content,H2O.ai,40.1858975,44.5073716,,Yerevan,,Armenia
517,Chang Liu,Ai-empowered persuasive video generation: A survey,Efficient user-generated video quality prediction,School of Computer Science,52.4501836,-1.9358404644161156,,Birmingham,England,United Kingdom
518,Shoubhik Debnath,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,FAIR,49.93216245,8.684753081266553,,Darmstadt,Hesse,Germany
519,Alison Noble,A kernel density estimation based quality metric for quality assessment of obstetric ultrasound video,Adaptive debanding filter,University of Oxford,51.75870755,-1.2556684826092037,Oxfordshire,Oxford,England,United Kingdom
520,Yongming Rao,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MAXIM: Multi-Axis MLP for Image Processing,Tencent,13.7871932,100.5746341,,Bangkok,,Thailand
521,Tian Meng,Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Electronic Information School,34.3825551,108.98153887655354,,Weiyang District,Shaanxi,China
522,"M. Emre Celebi, SPIE Fellow","Forty years of color quantization: a modern, algorithmic survey",Adaptive debanding filter,University of Central Arkansas,35.07764105,-92.45799264108024,Faulkner County,Conway,Arkansas,United States
523,Yi Jin,"Collaborative perception in autonomous driving: Methods, datasets, and challenges",CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,Beijing Jiaotong University,39.95044035,116.33606901092409,,Haidian District,Beijing,China
524,Wei Lu,A deep learning based no-reference quality assessment model for ugc videos,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
525,Liang Liao,Exploring the effectiveness of video perceptual representation in blind video quality assessment,A comparative evaluation of temporal pooling methods for blind video quality assessment,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
526,Chaofeng Chen,Exploring video quality assessment on user generated contents from aesthetic and technical perspectives,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
527,Wei Sun,A deep learning based no-reference quality assessment model for ugc videos,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
528,Yongming Rao,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MaxViT: Multi-axis Vision Transformer,Tencent,13.7871932,100.5746341,,Bangkok,,Thailand
529,Jelena Vlaović,Content dependent representation selection model for systems based on MPEG DASH,Content adaptive tiling method based on user access preference for streaming panoramic video,Sveučilište J. J. Strossmayera u Osijeku,45.5609202,18.6958797,Osijek-Baranja County,Osijek,,Croatia
530,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
531,Antonio Ortega,Rate-distortion optimization with alternative references for UGC video compression,Efficient user-generated video quality prediction,University of Southern California,34.02186895,-118.285857923125,Los Angeles County,Los Angeles,California,United States
532,Zhengzhong Tu,UGC-VQA: Benchmarking blind video quality assessment for user generated content,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
533,Runsheng Xu,V2v4real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,UCLA,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
534,Zhijian hao,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Fudan University,31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
535,Wei Dai,Vmaf and variants: Towards a unified vqa,Regression or classification? new methods to evaluate no-reference picture and video quality models,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
536,Yutong Wang,Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Institute of Automation,54.1720834,12.0790983,,Rostock,Mecklenburg-Vorpommern,Germany
537,long lan,Analysis of video quality datasets via design of minimalistic video quality models,Subjective quality assessment of user-generated content gaming videos,NUDT,28.229020900000002,112.99483204403164,,Kaifu,Hunan,China
538,Alan Bovik,A completely blind video quality evaluator,Regression or classification? new methods to evaluate no-reference picture and video quality models,Austin,30.2711286,-97.7436995,Travis County,Austin,Texas,United States
539,Ivan Bajic,Metaverse: A Young Gamer's Perspective,Subjective quality assessment of user-generated content gaming videos,Simon Fraser University,49.276709600000004,-122.91780296438841,Metro Vancouver Regional District,Burnaby,British Columbia,Canada
540,Qi Zheng,Blind Video Quality Assessment via Space-Time Slice Statistics,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
541,Wei Lu,A deep learning based no-reference quality assessment model for ugc videos,A comparative evaluation of temporal pooling methods for blind video quality assessment,Sun Yat-sen University,23.09960335,113.29235087324346,,Haizhu District,Guangdong Province,China
542,Guangtao Zhai,A deep learning based no-reference quality assessment model for ugc videos,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,Shanghai Jiao Tong University,31.200891149999997,121.4283949471511,,Xuhui District,Shanghai,China
543,Wenliang Zhao,Hornet: Efficient high-order spatial interactions with recursive gated convolutions,MAXIM: Multi-Axis MLP for Image Processing,Tsinghua University,40.002290450000004,116.3209629696906,,Haidian District,Beijing,China
544,Yanyu Li,Efficientformer: Vision transformers at mobilenet speed,MaxViT: Multi-axis Vision Transformer,Northeastern University,42.33895455,-71.08805803336392,Suffolk County,Boston,Massachusetts,United States
545,Chris Choy,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,NVIDIA,45.5344957,-122.886274,Washington County,Hillsboro,Oregon,United States
546,Avinab Saha,Study of subjective and objective quality assessment of mobile cloud gaming videos,Subjective quality assessment of user-generated content gaming videos,The University of Texas at Austin,30.27715345,-97.73440380486116,Travis County,Austin,Texas,United States
547,Meng Zonglin,HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR,V2X-ViT: Vehicle-to-everything cooperative perception with vision transformer,Los Angeles,34.0536909,-118.242766,Los Angeles County,Los Angeles,California,United States
548,Chaofeng Chen,Discovqa: Temporal distortion-content transformers for video quality assessment,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
549,Qi Zheng,Faver: Blind quality prediction of variable frame rate videos,BBAND Index: a No-Reference Banding Artifact Predictor,"Fudan University, Shanghai, China",31.30116485,121.49808756382322,,Yangpu District,Shanghai,China
550,Zicheng Zhang,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Shanghai Jiaotong University,31.2143785,121.4680316,,Shanghai,Shanghai,China
551,Zhi Li,Learning to distort images using generative adversarial networks,BBAND Index: a No-Reference Banding Artifact Predictor,Researcher,41.6567749,41.6398829,,Batumi,Autonomous Republic of Adjara,Georgia
552,Param Hanji,Robust estimation of exposure ratios in multi-exposure image stacks,BBAND Index: a No-Reference Banding Artifact Predictor,University of Cambridge,52.210945550000005,0.09200497637871279,Cambridgeshire,Cambridge,England,United Kingdom
553,Vishnu Pandi Chellapandi,Federated learning for connected and automated vehicles: A survey of existing approaches and challenges,V2V4Real: A real-world large-scale dataset for vehicle-to-vehicle cooperative perception,Cummins Inc.,39.2026383,-85.9212809,Bartholomew County,Columbus,Indiana,United States
554,Wenxiu Sun,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,UGC-VQA: Benchmarking blind video quality assessment for user generated content,Technology,3.16129015,101.56813112882818,,Petaling Jaya,Selangor,Malaysia
555,Duolikun Danier,BVI-VFI: A video quality database for video frame interpolation,FAVER: Blind Quality Prediction of Variable Frame Rate Videos,University of Edinburgh,55.94407645,-3.1883735563964555,,City of Edinburgh,Scotland,United Kingdom
556,Yuan-Gen Wang,Texture information boosts video quality assessment,Regression or classification? new methods to evaluate no-reference picture and video quality models,Guangzhou University,23.044604,113.36958610020251,,Panyu District,Guangdong Province,China
557,Ming-Hsuan Yang,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,Merced,37.1641544,-120.7678602,Merced County,,California,United States
558,Chaofeng Chen,Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling,Efficient user-generated video quality prediction,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
559,Zhi Li,Perceptual video quality prediction emphasizing chroma distortions,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
560,Chaofeng Chen,Q-align: Teaching lmms for visual scoring via discrete text-defined levels,RAPIQUE: Rapid and accurate video quality prediction of user generated content,Nanyang Technological University,1.3484104000000001,103.68293320728537,,Singapore,,Singapore
561,Shangchen Zhou,Flexicurve: Flexible piecewise curves estimation for photo retouching,Pik-Fix: Restoring and Colorizing Old Photos,NTU,25.01688615,121.53852099555085,,Taipei,,Taiwan
562,Sanghyun Woo,Convnext v2: Co-designing and scaling convnets with masked autoencoders,MaxViT: Multi-axis Vision Transformer,New York University,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
563,Tongyu Zong,Progressive Frame Patching for FoV-based Point Cloud Video Streaming,Content adaptive tiling method based on user access preference for streaming panoramic video,New York University,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
564,Zhengzhong Tu,RAPIQUE: Rapid and accurate video quality prediction of user generated content,A comparative evaluation of temporal pooling methods for blind video quality assessment,Texas A&M University,30.6108618,-96.35206061388457,Brazos County,College Station,Texas,United States
565,Jiaqi Ma,V2x-vit: Vehicle-to-everything cooperative perception with vision transformer,MaxViT: Multi-axis Vision Transformer,University of California,34.070877749999994,-118.44685070595054,Los Angeles County,Los Angeles,California,United States
566,Radu Timofte,The ninth NTIRE 2024 efficient super-resolution challenge report,MAXIM: Multi-Axis MLP for Image Processing,Computer Vision,23.0281188,89.4005223,Abhaynagar Upazila,,Khulna Division,Bangladesh
567,Woo Kyoung Han,ABCD: Arbitrary Bitwise Coefficient for De-quantization,Adaptive debanding filter,Korea University,36.6108905,127.2934246,,Sejong,,South Korea
568,Shengqian Han,Sight Guidance Enhanced VR Video Transmission,Content adaptive tiling method based on user access preference for streaming panoramic video,Beihang University (BUAA),39.9809427,116.34097867654876,,Haidian District,Beijing,China
569,Xiangxu YU,RAPIQUE: Rapid and accurate video quality prediction of user generated content,BBAND Index: a No-Reference Banding Artifact Predictor,Washington University in St. Louis,38.64724015,-90.30840174694748,Saint Louis County,St. Louis,Missouri,United States
570,Yiming Li,Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers,NYU,40.729205300000004,-73.99501481290962,New York County,New York,New York,United States
571,Li-Heng Chen,ProxIQA: A proxy approach to perceptual optimization of learned image compression,BBAND Index: a No-Reference Banding Artifact Predictor,Netflix Inc.,34.0891581,-118.333448,Los Angeles County,Los Angeles,California,United States
